{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d8ca0a0b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root added to path: /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Get the project root directory (two levels up from models/SpeechT5)\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
                "\n",
                "# Add project root to sys.path\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "print(f\"Project root added to path: {project_root}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "3673ce32",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/.venv/lib/python3.12/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
                        "  from pkg_resources import DistributionNotFound, get_distribution\n",
                        "Registered checkpoint save hook for _speechbrain_save\n",
                        "Registered checkpoint load hook for _speechbrain_load\n",
                        "Registered checkpoint save hook for save\n",
                        "Registered checkpoint load hook for load\n",
                        "Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
                        "Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
                        "Registered checkpoint save hook for _save\n",
                        "Registered checkpoint load hook for _recover\n"
                    ]
                }
            ],
            "source": [
                "from models.SpeechT5.evaluate_speecht5 import analyze"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "d985216d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n",
                        "Loading SpeechT5 model from /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/speecht5_en_de_partially_trained...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading SpeechT5 components...\n",
                        "Using device: cuda\n",
                        "Loading base model...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading Fleurs dataset (En & De)...\n",
                        "Initializing ASR (Whisper) for usage in metrics...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading google/fleurs (en_us) from local storage: /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/datasets/fleurs/en_us/train...\n",
                        "Slicing loaded dataset (0:2000)...\n",
                        "Loading google/fleurs (de_de) from local storage: /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/datasets/fleurs/de_de/train...\n",
                        "Slicing loaded dataset (0:2000)...\n",
                        "Validating en (checking audio & uniqueness)...\n",
                        "  1314 valid unique IDs found.\n",
                        "Validating de (checking audio & uniqueness)...\n",
                        "  1272 valid unique IDs found.\n",
                        "Final Count: 1118 common valid samples.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda\n",
                        "Loading metrics (BLEU, ROUGE, COMET)...\n",
                        "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 54755.93it/s]\n",
                        "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../../../../../home/zawiatgf/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
                        "Encoder model frozen.\n",
                        "/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/.venv/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
                        "Evaluating en -> de...\n",
                        "Fetch hyperparams.yaml: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/hyperparams.yaml'\n",
                        "Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing X-Vector classifier for embedding extraction...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Registered checkpoint save hook for _save\n",
                        "Registered checkpoint load hook for _load\n",
                        "Registered parameter transfer hook for _load\n",
                        "/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/.venv/lib/python3.12/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
                        "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
                        "Registered checkpoint save hook for save\n",
                        "Registered checkpoint load hook for load_if_possible\n",
                        "Collecting files (or symlinks) for pretraining in tmp_spkrec.\n",
                        "Fetch embedding_model.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt'\n",
                        "Set local path in self.paths[\"embedding_model\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt\n",
                        "Fetch mean_var_norm_emb.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt'\n",
                        "Set local path in self.paths[\"mean_var_norm_emb\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt\n",
                        "Fetch classifier.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt'\n",
                        "Set local path in self.paths[\"classifier\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt\n",
                        "Fetch label_encoder.txt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt'\n",
                        "Set local path in self.paths[\"label_encoder\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n",
                        "Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
                        "Redirecting (loading from local path): embedding_model -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt\n",
                        "Redirecting (loading from local path): mean_var_norm_emb -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt\n",
                        "Redirecting (loading from local path): classifier -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt\n",
                        "Redirecting (loading from local path): label_encoder -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n",
                        "Loaded categorical encoding from /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting target speaker embedding...\n",
                        "Streaming 1 sample from google/fleurs for de...\n",
                        "Embedding extracted successfully.\n",
                        "Cleaning up speaker classifier to free VRAM...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "en->de:   0%|          | 0/1118 [00:00<?, ?it/s]/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/model.py:221: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  emb = torch.tensor(speaker_embedding).to(self.device).unsqueeze(0)\n",
                        "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
                        "en->de:   1%|          | 10/1118 [00:18<35:19,  1.91s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
                        "en->de:  35%|███▍      | 388/1118 [14:20<35:14,  2.90s/it]  Error at index 388: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "en->de: 100%|██████████| 1118/1118 [41:03<00:00,  2.20s/it]\n",
                        "Evaluating de -> en...\n",
                        "Fetch hyperparams.yaml: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/hyperparams.yaml'\n",
                        "Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing X-Vector classifier for embedding extraction...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Collecting files (or symlinks) for pretraining in tmp_spkrec.\n",
                        "Fetch embedding_model.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt'\n",
                        "Set local path in self.paths[\"embedding_model\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt\n",
                        "Fetch mean_var_norm_emb.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt'\n",
                        "Set local path in self.paths[\"mean_var_norm_emb\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt\n",
                        "Fetch classifier.ckpt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt'\n",
                        "Set local path in self.paths[\"classifier\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt\n",
                        "Fetch label_encoder.txt: Using symlink found at '/media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt'\n",
                        "Set local path in self.paths[\"label_encoder\"] = /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n",
                        "Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
                        "Redirecting (loading from local path): embedding_model -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/embedding_model.ckpt\n",
                        "Redirecting (loading from local path): mean_var_norm_emb -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/mean_var_norm_emb.ckpt\n",
                        "Redirecting (loading from local path): classifier -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/classifier.ckpt\n",
                        "Redirecting (loading from local path): label_encoder -> /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n",
                        "Loaded categorical encoding from /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/models/SpeechT5/tmp_spkrec/label_encoder.ckpt\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting target speaker embedding...\n",
                        "Streaming 1 sample from google/fleurs for en...\n",
                        "Embedding extracted successfully.\n",
                        "Cleaning up speaker classifier to free VRAM...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "de->en:  13%|█▎        | 148/1118 [05:18<35:31,  2.20s/it]  Error at index 148: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "de->en:  17%|█▋        | 195/1118 [06:56<1:07:58,  4.42s/it]Error at index 195: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "de->en:  35%|███▍      | 388/1118 [13:28<22:06,  1.82s/it]  Error at index 388: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "de->en:  46%|████▋     | 519/1118 [17:56<17:09,  1.72s/it]  Error at index 519: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "de->en:  78%|███████▊  | 875/1118 [29:25<08:14,  2.04s/it]Error at index 875: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n",
                        "de->en: 100%|██████████| 1118/1118 [37:31<00:00,  2.01s/it]\n",
                        "Computing metrics...\n",
                        "Using default tokenizer.\n",
                        "Using default tokenizer.\n",
                        "Saving results to /media/zawiatgf/New Volume/Personal Files/Abdurrahman Zawia/University/Grad Project/Speech-To-Speech-Model/speecht5.json...\n",
                        "Evaluation Complete.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "    \"en_to_de\": {\n",
                        "        \"bleu\": {\n",
                        "            \"score\": 0.23443066865389942,\n",
                        "            \"counts\": [\n",
                        "                2087,\n",
                        "                205,\n",
                        "                28,\n",
                        "                6\n",
                        "            ],\n",
                        "            \"totals\": [\n",
                        "                40971,\n",
                        "                39854,\n",
                        "                38737,\n",
                        "                37623\n",
                        "            ],\n",
                        "            \"precisions\": [\n",
                        "                5.093846867296381,\n",
                        "                0.5143774777939479,\n",
                        "                0.07228231406665463,\n",
                        "                0.015947691571645006\n",
                        "            ],\n",
                        "            \"bp\": 1.0,\n",
                        "            \"sys_len\": 40971,\n",
                        "            \"ref_len\": 23611\n",
                        "        },\n",
                        "        \"rouge\": {\n",
                        "            \"rouge1\": 0.11323484395632454,\n",
                        "            \"rouge2\": 0.021463270795777624,\n",
                        "            \"rougeL\": 0.10169722708026116,\n",
                        "            \"rougeLsum\": 0.10196174933018282\n",
                        "        },\n",
                        "        \"comet\": {\n",
                        "            \"mean_score\": 0.0\n",
                        "        }\n",
                        "    },\n",
                        "    \"de_to_en\": {\n",
                        "        \"bleu\": {\n",
                        "            \"score\": 0.051175081335617115,\n",
                        "            \"counts\": [\n",
                        "                2057,\n",
                        "                47,\n",
                        "                1,\n",
                        "                0\n",
                        "            ],\n",
                        "            \"totals\": [\n",
                        "                30670,\n",
                        "                29557,\n",
                        "                28444,\n",
                        "                27334\n",
                        "            ],\n",
                        "            \"precisions\": [\n",
                        "                6.706879686990544,\n",
                        "                0.15901478499171093,\n",
                        "                0.003515679932498945,\n",
                        "                0.0018292236774712812\n",
                        "            ],\n",
                        "            \"bp\": 1.0,\n",
                        "            \"sys_len\": 30670,\n",
                        "            \"ref_len\": 23352\n",
                        "        },\n",
                        "        \"rouge\": {\n",
                        "            \"rouge1\": 0.09759133221172564,\n",
                        "            \"rouge2\": 0.0037235894713190595,\n",
                        "            \"rougeL\": 0.08313788652356452,\n",
                        "            \"rougeLsum\": 0.08316276536500279\n",
                        "        },\n",
                        "        \"comet\": {\n",
                        "            \"mean_score\": 0.0\n",
                        "        }\n",
                        "    }\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "# Run the analysis\n",
                "analyze(num_samples=2000) "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
